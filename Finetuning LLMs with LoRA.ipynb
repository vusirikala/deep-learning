{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1a0560e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (2.4.0)\n",
      "Requirement already satisfied: transformers in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (4.44.0)\n",
      "Requirement already satisfied: datasets in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: peft in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (0.12.0)\n",
      "Requirement already satisfied: evaluate in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (0.4.2)\n",
      "Requirement already satisfied: numpy in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (1.26.4)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: setuptools in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from datasets) (3.10.3)\n",
      "Requirement already satisfied: psutil in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from peft) (0.33.0)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading scikit_learn-1.5.1-cp312-cp312-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m826.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.14.0-cp312-cp312-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m921.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 scipy-1.14.0 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers datasets peft evaluate numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1eefe02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1add65c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "071e749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1072562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = 'distilbert-base-uncased'\n",
    "id2label = {0: 'Negative', 1: 'Positive'}\n",
    "label2id = {'Negative': 0, 'Positive': 1}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b37b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('shawhin/imdb-truncated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f964430c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f139ea90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': '. . . or type on a computer keyboard, they\\'d probably give this eponymous film a rating of \"10.\" After all, no elephants are shown being killed during the movie; it is not even implied that any are hurt. To the contrary, the master of ELEPHANT WALK, John Wiley (Peter Finch), complains that he cannot shoot any of the pachyderms--no matter how menacing--without a permit from the government (and his tone suggests such permits are not within the realm of probability). Furthermore, the elements conspire--in the form of an unusual drought and a human cholera epidemic--to leave the Wiley plantation house vulnerable to total destruction by the Elephant People (as the natives dub them) to close the story. If you happen to see the current release EARTH, you\\'ll detect the Elephant People are faring less well today.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "142af124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2f16add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 6617.48 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 7952.22 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function converts text to numbers\n",
    "def tokenize_function(examples):\n",
    "    text = examples['text']\n",
    "    \n",
    "    # We need to make sure the examples are all of same length.\n",
    "    # We can either do this by truncating long sequences or padding long sequences to fixed length.\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(text, return_tensors='np', truncation=True, max_length=512)\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Add pad token if none exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    # Update the model to handle the additional token we just added\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "# Tokenize training and validation datasets\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8c4f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data collator. \n",
    "# Dynamically pads the examples in a given batch to the longest sequence in the batch\n",
    "# Using the collator to pad the examples in each batch is more efficient than padding all\n",
    "# the examples across the entire training set as there could be some anomalies with extremely long\n",
    "# sequence length\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02c803a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how we monitor the performance of the model during training\n",
    "\n",
    "# import accuracy evaluation metric\n",
    "accuracy = evaluate.load('accuracy')\n",
    "\n",
    "# packaging evaluation metrics into a function\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # computing accuracy by comparing prediction with label\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e4455b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model predictions:\n",
      "----------------------------\n",
      "It was good - Negative\n",
      "Not a fan, don't recommend - Negative\n",
      "Better than the first one - Negative\n",
      "This is not worth watching even once - Negative\n",
      "This one is a pass - Negative\n"
     ]
    }
   ],
   "source": [
    "text_list = [\"It was good\", \n",
    "             \"Not a fan, don't recommend\", \n",
    "             \"Better than the first one\",\n",
    "             \"This is not worth watching even once\",\n",
    "             \"This one is a pass\"\n",
    "            ]\n",
    "\n",
    "print(\"Untrained model predictions:\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.argmax(logits)\n",
    "    \n",
    "    print(text + \" - \" + id2label[predictions.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1da0f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\", # sequence classification\n",
    "                        r=4,  # intrinsic rank of traininable weight matrix\n",
    "                        lora_alpha=32, # this is like a learning rate\n",
    "                        lora_dropout=0.01, # probability of dropout\n",
    "                        target_modules=['q_lin']) # we apply lora to query layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "815ae8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9307\n",
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "# From the original model, we get another model that is ready to be finetuned using LoRA\n",
    "model = get_peft_model(model, peft_config)\n",
    "model = model.to(device) # moving to 'mps' for Mac (can alternatively do 'cpu')\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c71b11cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satyavusirikala/work/aptos/aptos-core/.venv/lib/python3.12/site-packages/transformers/training_args.py:2179: UserWarning: `use_mps_device` is deprecated and will be removed in version 5.0 of 🤗 Transformers. `mps` device will be used by default if available similar to the way `cuda` device is used.Therefore, no action from user is required. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "lr = 1e-3  # size of optimization step\n",
    "batch_size = 4 # number of examples processed per optimization step\n",
    "num_epochs = 10 # number of times model runs through training data\n",
    "\n",
    "# define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = model_checkpoint + \"-lora-text-classification\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\", # compute the evaluation metrics for each epoch\n",
    "    save_strategy=\"epoch\", # save the model parameters for each epoch\n",
    "    load_best_model_at_end=True, # at the end of training, return the best version of the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceda4d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 10%|█         | 250/2500 [01:54<08:54,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5735306143760681, 'eval_accuracy': {'accuracy': 0.843}, 'eval_runtime': 43.5504, 'eval_samples_per_second': 22.962, 'eval_steps_per_second': 5.74, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 500/2500 [03:00<08:30,  3.92it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4415, 'grad_norm': 19.244827270507812, 'learning_rate': 0.0008, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 20%|██        | 500/2500 [03:31<08:30,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4678434431552887, 'eval_accuracy': {'accuracy': 0.879}, 'eval_runtime': 30.6719, 'eval_samples_per_second': 32.603, 'eval_steps_per_second': 8.151, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 30%|███       | 750/2500 [05:06<07:31,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.626606822013855, 'eval_accuracy': {'accuracy': 0.882}, 'eval_runtime': 31.2583, 'eval_samples_per_second': 31.992, 'eval_steps_per_second': 7.998, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1000/2500 [06:06<05:08,  4.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2188, 'grad_norm': 0.3092513084411621, 'learning_rate': 0.0006, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 40%|████      | 1000/2500 [06:38<05:08,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7080491185188293, 'eval_accuracy': {'accuracy': 0.883}, 'eval_runtime': 32.1543, 'eval_samples_per_second': 31.1, 'eval_steps_per_second': 7.775, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 50%|█████     | 1250/2500 [08:06<04:28,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7667421698570251, 'eval_accuracy': {'accuracy': 0.889}, 'eval_runtime': 32.7305, 'eval_samples_per_second': 30.553, 'eval_steps_per_second': 7.638, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1500/2500 [09:00<02:53,  5.76it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0905, 'grad_norm': 0.000760614697355777, 'learning_rate': 0.0004, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 60%|██████    | 1500/2500 [09:31<02:53,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8285343647003174, 'eval_accuracy': {'accuracy': 0.889}, 'eval_runtime': 30.7065, 'eval_samples_per_second': 32.566, 'eval_steps_per_second': 8.142, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 70%|███████   | 1750/2500 [11:02<02:40,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0264489650726318, 'eval_accuracy': {'accuracy': 0.884}, 'eval_runtime': 37.2415, 'eval_samples_per_second': 26.852, 'eval_steps_per_second': 6.713, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 2000/2500 [11:56<01:50,  4.53it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0319, 'grad_norm': 4.4457610783865675e-06, 'learning_rate': 0.0002, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 80%|████████  | 2000/2500 [12:33<01:50,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9506431818008423, 'eval_accuracy': {'accuracy': 0.885}, 'eval_runtime': 36.1754, 'eval_samples_per_second': 27.643, 'eval_steps_per_second': 6.911, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 90%|█████████ | 2250/2500 [14:13<00:48,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9696640968322754, 'eval_accuracy': {'accuracy': 0.891}, 'eval_runtime': 37.7728, 'eval_samples_per_second': 26.474, 'eval_steps_per_second': 6.619, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [15:13<00:00,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0044, 'grad_norm': 0.0002933680370915681, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 2500/2500 [15:47<00:00,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9987988471984863, 'eval_accuracy': {'accuracy': 0.886}, 'eval_runtime': 33.7178, 'eval_samples_per_second': 29.658, 'eval_steps_per_second': 7.414, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [15:48<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 948.1841, 'train_samples_per_second': 10.546, 'train_steps_per_second': 2.637, 'train_loss': 0.15740664529800416, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2500, training_loss=0.15740664529800416, metrics={'train_runtime': 948.1841, 'train_samples_per_second': 10.546, 'train_steps_per_second': 2.637, 'total_flos': 1112883852759936.0, 'train_loss': 0.15740664529800416, 'epoch': 10.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a custom collate function to move tensors to the MPS device\n",
    "class CustomTrainer(Trainer):\n",
    "    def _prepare_inputs(self, inputs):\n",
    "        return {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # def compute_loss(self, model, inputs, return_outputs=False):\n",
    "    #         inputs = self._prepare_inputs(inputs)\n",
    "    #         return super().compute_loss(model, inputs, return_outputs)\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # Move inputs to the correct device\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "        # Get the loss\n",
    "        loss = outputs.get(\"loss\")\n",
    "        # Ensure the loss is on the correct device\n",
    "        if loss is not None:\n",
    "            loss = loss.to(device)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "trainer = CustomTrainer(\n",
    "    model=model, # our peft model\n",
    "    args=training_args, # hyperparameter\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator, # this will dynamically pad examples\n",
    "    compute_metrics=compute_metrics, # evaluate metrics using this function\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ddb47bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model predictions:\n",
      "----------------------------\n",
      "It was good - Positive\n",
      "Not a fan, don't recommend - Negative\n",
      "Better than the first one - Positive\n",
      "This is not worth watching even once - Negative\n",
      "This one is a pass - Negative\n"
     ]
    }
   ],
   "source": [
    "text_list = [\"It was good\", \n",
    "             \"Not a fan, don't recommend\", \n",
    "             \"Better than the first one\",\n",
    "             \"This is not worth watching even once\",\n",
    "             \"This one is a pass\"\n",
    "            ]\n",
    "\n",
    "print(\"Trained model predictions:\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    logits = model(inputs.to(device)).logits\n",
    "    predictions = torch.argmax(logits)\n",
    "    \n",
    "    print(text + \" - \" + id2label[predictions.tolist()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
